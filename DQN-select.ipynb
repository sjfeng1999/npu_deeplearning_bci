{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import datetime\n",
    "import random \n",
    "import copy \n",
    "import gc\n",
    "import sys\n",
    "sys.path.append(\"rl_method\")\n",
    "import env\n",
    "import agent\n",
    "import preprocess\n",
    "\n",
    "import load_data\n",
    "import utils\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/willer/Desktop/Development/Python/MyRepo/npu-deeplearning-bci/model/PretrainNet_T1.pkl'\n",
    "enet = preprocess.EncodeNet_T()\n",
    "pnet = preprocess.PretrainNet_T()\n",
    "pnet.load_state_dict(torch.load(model_path))\n",
    "\n",
    "enet_dict = enet.state_dict()\n",
    "for (name, param) in enet_dict.items():\n",
    "    enet_dict[name] = copy.deepcopy(pnet.state_dict()[name])\n",
    "enet.load_state_dict(enet_dict)\n",
    "enet.eval()\n",
    "\n",
    "n_classes = 2\n",
    "ndata, nlabel = load_data.get_grazdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlabel = nlabel.reshape(-1, 1)\n",
    "train_loader, test_loader = load_data.boost_dataloader(ndata, nlabel, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48416, 10, 128) (48416, 2)\n"
     ]
    }
   ],
   "source": [
    "enet.to(torch.device('cuda'))\n",
    "ndata = None\n",
    "nlabel = None\n",
    "with torch.no_grad():\n",
    "    for input, label in train_loader:\n",
    "        output = enet(input).cpu().numpy()\n",
    "        label = label.cpu().numpy().reshape(-1)\n",
    "        vec_label = np.eye(n_classes)[label]\n",
    "        \n",
    "        if str(type(ndata)) == \"<class 'NoneType'>\":\n",
    "            ndata  = output\n",
    "            nlabel = vec_label\n",
    "        else:\n",
    "            ndata  = np.concatenate([ndata, output], 0)\n",
    "            nlabel = np.concatenate([nlabel, vec_label], 0)\n",
    "\n",
    "    for input, label in test_loader:\n",
    "        output = enet(input).cpu().numpy()\n",
    "        label = label.cpu().numpy().reshape(-1)\n",
    "        vec_label = np.eye(n_classes)[label]\n",
    "\n",
    "        ndata  = np.concatenate([ndata, output], 0)\n",
    "        nlabel = np.concatenate([nlabel, vec_label], 0)\n",
    "\n",
    "print(ndata.shape, nlabel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('rl_method/encode_data/encode_data_tem1.npy', ndata)\n",
    "np.save('rl_method/encode_data/encode_label_tem1.npy', nlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndata = np.load('rl_method/encode_data/encode_data_tem1.npy')\n",
    "nlabel = np.load('rl_method/encode_data/encode_label_tem1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_reward_net(input_size, model_path):\n",
    "\n",
    "    rnet = RewardNet(input_size)\n",
    "    pnet = PretrainNet_T()\n",
    "    pnet.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    rnet_dict = rnet.state_dict()\n",
    "    for (name, param)  in rnet_dict.items():\n",
    "        rnet_dict[name] = copy.deepcopy(pnet.state_dict()[name])\n",
    "    rnet.load_state_dict(rnet_dict)\n",
    "    rnet.eval()\n",
    "    return rnet\n",
    "\n",
    "class PretrainNet_T(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channel=3,\n",
    "        sequence_lens=1000,\n",
    "        time_lens=10,\n",
    "        hidden_size=64,\n",
    "        output_size=2,\n",
    "        layer_size=1,\n",
    "        bidirectional=True\n",
    "    ):\n",
    "        super(PretrainNet_T, self).__init__()\n",
    "\n",
    "        if sequence_lens % time_lens != 0:\n",
    "            raise ValueError(\"Invalid time lens\")\n",
    "\n",
    "        self.in_channel  = in_channel\n",
    "        self.time_lens   = time_lens\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer_size  = layer_size\n",
    "        self.window_size = sequence_lens // time_lens\n",
    "        self.device      = torch.device('cuda')\n",
    "\n",
    "        self.subconv    = SubConvNet(in_channel=in_channel, out_channel=4)\n",
    "        self.input_size = self._adaptive_feature_size()\n",
    "\n",
    "        self.lstm = nn.LSTM(self.input_size, hidden_size, layer_size, bidirectional=bidirectional)\n",
    "        if bidirectional:\n",
    "            self.layer_size *= 2\n",
    "\n",
    "        self.fn1  = nn.Linear(hidden_size * self.layer_size, 128)\n",
    "        self.fn2  = nn.Linear(128, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        x = x.chunk(self.time_lens, 2)\n",
    "        x = torch.stack(x, 1)\n",
    "        x = x.reshape(batch_size * self.time_lens, self.in_channel, self.window_size)\n",
    "\n",
    "        x = self.subconv(x)\n",
    "        x = x.view(batch_size, self.time_lens, self.input_size)\n",
    "        x = x.permute(1, 0, 2)\n",
    "\n",
    "        h_0 = torch.zeros(self.layer_size, batch_size, self.hidden_size).to(self.device)\n",
    "        c_0 = torch.zeros(self.layer_size, batch_size, self.hidden_size).to(self.device)\n",
    "        x, (h_final, c_final) = self.lstm(x, (h_0, c_0))\n",
    "        # seq, batch, feature\n",
    "        x = x.permute(1, 2, 0)\n",
    "\n",
    "        x = F.avg_pool1d(x, self.time_lens)\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = F.relu(self.fn1(x), inplace=True)\n",
    "        x = F.softmax(self.fn2(x), dim=-1)\n",
    "        return x\n",
    "\n",
    "    def _adaptive_feature_size(self):\n",
    "        x = torch.zeros(1, self.in_channel, self.window_size)\n",
    "        return self.subconv(x).view(-1).shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess\n",
    "def calculate_reward(vector_a, vector_b):\n",
    "    return -np.sum(np.abs(vector_a - vector_b))\n",
    "\n",
    "def cal_cosine_similarity(vector_a, vector_b):\n",
    "    inner = np.dot(vector_a, vector_b.transpose())\n",
    "    norm = np.linalg.norm(vector_a) * np.linalg.norm(vector_b)\n",
    "    return inner / norm\n",
    "\n",
    "class FeatureManager:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.size = data.shape[-1]\n",
    "        self.index = list(range(data.shape[0]))\n",
    "\n",
    "    def drop(self, action):\n",
    "        self.index.remove(self.index[action])\n",
    "\n",
    "    def state(self):\n",
    "        new_state = self.data[self.index]\n",
    "        new_size  = new_state.shape[0]\n",
    "        new_index = list(range(new_size))\n",
    "\n",
    "        avg_state = torch.mean(new_state, 0)\n",
    "        ret_state = []\n",
    "        for i in range(new_size):\n",
    "            remaining = new_state[new_index[:i] + new_index[i+1:]]\n",
    "            mean_state, var_state = self.mean_var_state(remaining)\n",
    "            ret_state.append([new_state[i], mean_state, var_state])\n",
    "        return avg_state, ret_state\n",
    "\n",
    "    def mean_var_state(self, remaining_feature):\n",
    "        shape = remaining_feature.shape[1]\n",
    "        size  = remaining_feature.shape[0]\n",
    "        mean_state = torch.mean(remaining_feature, 0)\n",
    "        var_state  = torch.mean(torch.pow(remaining_feature - mean_state, 2), 0)\n",
    "        return mean_state, var_state\n",
    "\n",
    "\n",
    "class DropEnv:\n",
    "    def __init__(self, tdata, vdata, tlabel, vlabel, drop_reward, reward_model_path):\n",
    "\n",
    "        self.drop_reward = drop_reward\n",
    "        self.random_stop = 0.8\n",
    "        self.training = True\n",
    "        \n",
    "        self.tdata  = torch.from_numpy(tdata)\n",
    "        self.vdata  = torch.from_numpy(vdata)\n",
    "        self.tlabel = tlabel\n",
    "        self.vlabel = vlabel\n",
    "        \n",
    "        self.tdata_size = self.tdata.shape[0]\n",
    "        self.vdata_size = self.vdata.shape[0]\n",
    "        self.channel_size = self.tdata.shape[1]\n",
    "        \n",
    "        self.reward_module = get_reward_net(tdata[0].shape[-1], reward_model_path)\n",
    "\n",
    "    def step(self, action):\n",
    "        self.manager.drop(action)\n",
    "        avg_state, state = self.manager.state()\n",
    "        cls_vector = self.reward_module(avg_state).numpy()\n",
    "        self.new_sim = calculate_reward(cls_vector, self.current_label)\n",
    "        if self.training:\n",
    "            reward = self.new_sim - self.old_sim + self.drop_reward\n",
    "        else:\n",
    "            reward = self.new_sim - self.old_sim\n",
    "        self.old_sim = self.new_sim\n",
    "\n",
    "        done = False\n",
    "        if reward < 0 and (self.training == True and random.random() < self.random_stop \\\n",
    "                           or self.training == False):\n",
    "            done = True\n",
    "        \n",
    "        if self.training:\n",
    "            return state, reward, done\n",
    "        else:\n",
    "            res = np.argmax(cls_vector)\n",
    "            return state, float(res==self.current_num), done\n",
    "\n",
    "    def train(self):\n",
    "        self.training = True\n",
    "\n",
    "    def eval(self):\n",
    "        self.training = False\n",
    "\n",
    "    def reset(self):\n",
    "        if self.training:\n",
    "            index = random.randint(0, self.tdata_size-1)\n",
    "            single_data = self.tdata[index]\n",
    "            self.current_label = self.tlabel[index]\n",
    "        else:\n",
    "            index = random.randint(0, self.vdata_size-1)\n",
    "            single_data = self.vdata[index]\n",
    "            self.current_label = self.vlabel[index]\n",
    "            \n",
    "        self.current_num = np.argmax(self.current_label)\n",
    "        self.manager = FeatureManager(single_data)\n",
    "            \n",
    "        random_drop_num = 0\n",
    "        \n",
    "        if self.training:\n",
    "            random_drop_num = random.randint(1, self.channel_size//4)\n",
    "            random_drop_idx = random.sample(range(0, self.channel_size - random_drop_num - 1), random_drop_num)\n",
    "            for idx in random_drop_idx:\n",
    "                self.manager.drop(idx)\n",
    "\n",
    "        init_avg_state, init_state = self.manager.state()\n",
    "        init_cls_vector = self.reward_module(init_avg_state).numpy()\n",
    "        init_cls_num = np.argmax(init_cls_vector)\n",
    "        self.old_sim = calculate_reward(init_cls_vector, self.current_label)\n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "        if self.training:\n",
    "            return init_state, random_drop_num\n",
    "        else:\n",
    "            return init_state, float(init_cls_num==self.current_num), random_drop_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndata = ndata[:1000]\n",
    "nlabel = nlabel[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/willer/Desktop/Development/Python/MyRepo/npu-deeplearning-bci/model/PretrainNet_T1.pkl'\n",
    "agent = ADAgent(ndata, nlabel, model_path, train_epoch=8000)\n",
    "agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_origin(action):\n",
    "    res = [0 for i in range(10)]\n",
    "    map_move = 0\n",
    "    for act in action:\n",
    "        res[act + map_move] += 1\n",
    "        map_move += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 2, 0, 1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_to_origin([1,2,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0, 1])\n",
    "b = np.array([0.1, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
